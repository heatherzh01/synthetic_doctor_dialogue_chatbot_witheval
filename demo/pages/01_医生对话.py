import json
import streamlit as st
import numpy as np
from src.session import Session
from src.utils.io import load_objection_case_from_yaml, load_rep_from_yaml, load_hcp_from_dict
from src.static_classes import VirtualHcp, ObjectionInstance
from audio.tts.openai_tts import tts_openai
import sys
sys.path.append('..')


st.set_page_config(
    page_title="Welcome to NovoNordisk ChatHCP",
    page_icon="ğŸ‘‹",
)

MAX_LEN_FILENAME = 64
st.markdown('''### :green[è™šæ‹ŸåŒ»ç”Ÿå¯¹è¯]''')
col1, col2, col3, col4 = st.columns(4)
with col1:
    use_monitor = st.toggle('ç»ƒä¹ æ¨¡å¼')
if use_monitor:
    with col2:
        select_hcp = st.toggle('æŒ‡å®šè™šæ‹ŸåŒ»ç”Ÿ')
    with col3:
        select_real = st.toggle('æŒ‡å®šçœŸå®å¼‚è®®')
with col4:
    open_voice = st.toggle('è¯­éŸ³æ¨¡å¼')

rep_file = st.sidebar.selectbox('è¯·ç™»å½•æ‚¨çš„è´¦æˆ·', options=['001_EdgarCao', '002_AndrewYu'])
objection_file = st.sidebar.selectbox('è¯·é€‰æ‹©å¼‚è®®é¢˜ç›®', options=[
    '001_SGLT-2iå’Œè¯ºå’Œæ³°éƒ½æ˜¯æœ‰å¿ƒè¡€ç®¡è·ç›Šçš„è¯ç‰©',
    '002_è¯ºå’Œæ³°æœ‰èƒƒè‚ é“ååº”å¤§ï¼Œå¤„ç†èµ·æ¥éº»çƒ¦',
    '003_æ‚£è€…HbA1cå·²ç»è¾¾æ ‡ï¼Œæ²¡å¿…è¦å†å»è°ƒæ•´åŸæ¥çš„é™ç³–æ–¹æ¡ˆäº†',
    '004_æ‚£è€…ç›®å‰çš„é™ç³–æ–¹æ¡ˆå¤æ‚ï¼Œå†åŠ ç”¨è¯ºå’Œæ³°ï¼Œè°ƒæ•´èµ·æ¥å¾ˆéº»çƒ¦',
    '005_è¯ºå’Œæ³°éœ€è¦æ³¨å°„ï¼Œä¸å¥½è¯´æœæ‚£è€…'
])
rep = load_rep_from_yaml(f'../data/reps/{rep_file}.yml')
objection = load_objection_case_from_yaml(f'../data/objections/{objection_file}.yml')

if use_monitor and select_real:
    selected_real_objection_name = st.selectbox('è¯·é€‰æ‹©çœŸå®å¼‚è®®(è°œåº•)', options=[x['name'] for x in objection.real_objection])
    selected_real_objection = [x for x in objection.real_objection if x['name'] == selected_real_objection_name][0]
else:
    selected_real_objection = np.random.choice(objection.real_objection)
objection.selected_real_objection = selected_real_objection

objection_instance = ObjectionInstance(
    preset_objection=objection.preset_objection,
    real_objection=objection.selected_real_objection['name'],
    clarify_type=objection.selected_real_objection['clarify_type'],
    take_action_type=objection.selected_real_objection['take_action_type'],
    visible_background=objection.selected_real_objection['visible_extra_info'],         # å¯è§èƒŒæ™¯ä¿¡æ¯
    invisible_background=objection.selected_real_objection['invisible_extra_info'],     # ä¸å¯è§èƒŒæ™¯ä¿¡æ¯
    standard_answer=objection.selected_real_objection['standard_answer']                # è§£å†³é˜¶æ®µè¦ç‚¹
)

hcp_attr = {}
if use_monitor and select_hcp:
    col1, col2, col3 = st.columns(3)
    with col1:
        hcp_attr['hcp_dept'] = st.selectbox('è¯·é€‰æ‹©è™šæ‹ŸåŒ»ç”Ÿç§‘å®¤', options=objection.hcp_space['hcp_dept'])
        hcp_attr['hcp_type'] = st.selectbox('è¯·é€‰æ‹©è™šæ‹ŸåŒ»ç”Ÿç±»å‹', options=objection.hcp_space['hcp_type'])
    with col2:
        hcp_attr['hcp_scene'] = st.selectbox('è¯·é€‰æ‹©è™šæ‹Ÿå¯¹è¯åœºæ™¯', options=objection.hcp_space['hcp_scene'])
        hcp_attr['hcp_personality'] = st.selectbox('è¯·é€‰æ‹©è™šæ‹ŸåŒ»ç”Ÿæ€§æ ¼', options=objection.hcp_space['hcp_personality'])
    with col3:
        hcp_attr['hcp_knowledge_stage'] = st.selectbox('è¯·é€‰æ‹©è™šæ‹ŸåŒ»ç”Ÿè®¤çŸ¥é˜¶æ¢¯', options=objection.hcp_space['hcp_knowledge_stage'])
else:
    hcp_attr['hcp_dept'] = np.random.choice(objection.hcp_space['hcp_dept'])
    hcp_attr['hcp_type'] = np.random.choice(objection.hcp_space['hcp_type'])
    hcp_attr['hcp_scene'] = np.random.choice(objection.hcp_space['hcp_scene'])
    hcp_attr['hcp_personality'] = np.random.choice(objection.hcp_space['hcp_personality'])
    hcp_attr['hcp_knowledge_stage'] = np.random.choice(objection.hcp_space['hcp_knowledge_stage'])
    # hcp_attr['hcp_opinion'] = np.random.choice(objection.hcp_space['hcp_opinion'])
    # hcp_attr['hcp_patients'] = objection.hcp_space['hcp_patients']
objection_instance.visible_background = f'''æ³¨æ„ä½ æ˜¯ä¸€å{hcp_attr['hcp_dept']}åŒ»ç”Ÿï¼Œä¸€å{hcp_attr['hcp_type']}åŒ»ç”Ÿã€‚è¿™æ®µå¯¹è¯å‘ç”Ÿåœ¨{hcp_attr['hcp_scene']}åœºæ™¯ã€‚æ‚¨å¯¹è¯ºå’Œæ³°çš„ä½¿ç”¨å±äº{hcp_attr['hcp_knowledge_stage']}'''
hcp = load_hcp_from_dict(**hcp_attr)

# res_style = st.sidebar.selectbox('è¯·é€‰æ‹©åŒ»ç”Ÿå¯¹ç¡®è®¤å¼‚è®®çš„ååº”æ¨¡å¼', options=['å¤§æ–¹æ‰¿è®¤', 'æ”¯æ”¯å¾å¾', 'èƒ¡ç¼–ä¹±é€ ', 'æ··åˆæ¨¡å¼'])
use_dept_knowledge = st.sidebar.selectbox('è™šæ‹ŸåŒ»ç”Ÿæ˜¯å¦å¯ç”¨ä¸“ç§‘çŸ¥è¯†åº“', options=[True, False])
use_product_knowledge = st.sidebar.selectbox('è™šæ‹ŸåŒ»ç”Ÿæ˜¯å¦å¯ç”¨è¯ºå’Œæ³°çŸ¥è¯†åº“', options=[True, False])

llm = st.sidebar.selectbox('è¯·é€‰æ‹©åŸºåº§æ¨¡å‹', options=['gpt-4-0125-preview', 'gpt-3.5-turbo'])
temp = st.sidebar.slider('è¯·é€‰æ‹©ç”Ÿæˆè¯­è¨€æ¸©åº¦', 0.0, 2.0, value=1.2, step=0.05)
frequency_penalty = st.sidebar.slider('frequency_penalty', -2.0, 2.0, value=1.5, step=0.05)
presence_penalty = st.sidebar.slider('presence_penalty', -2.0, 2.0, value=1.5, step=0.05)
llm_params = {'temperature': temp, 'frequency_penalty': frequency_penalty, 'presence_penalty': presence_penalty}

col1, col2, col3 = st.columns([3, 1, 1])
with col1:
    if use_monitor:
        st.markdown('''#### ç»ƒä¹ æ¨¡å¼''')
    else:
        st.markdown('''#### æµ‹è¯•æ¨¡å¼''')
with col2:
    if st.button('æ–°å»ºèŠå¤©å¯¹è¯'):
        del st.session_state['chat_session']
with col3:
    if st.button('ä¿å­˜å½“å‰å¯¹è¯'):
        st.session_state.chat_session.save('../output/chat_history')

if 'chat_session' not in st.session_state:
    st.session_state.image_path = f'../data/images/{hcp.hcp_gender}åŒ»ç”Ÿ.jpg'
    session = Session(
        rep=rep,
        hcp=hcp,
        objection=objection_instance,
        tts='openai',
        use_dept_knowledge=use_dept_knowledge,
        use_product_knowledge=use_product_knowledge,
        monitor=True,
        llm=llm,
        llm_params=llm_params
    )
    st.session_state['chat_session'] = session

with st.expander('ç‚¹å‡»å±•å¼€å¼‚è®®èƒŒæ™¯', expanded=False):

    st.markdown(f'##### æ¬¢è¿ä½¿ç”¨è™šæ‹ŸåŒ»ç”Ÿå¯¹è¯æœºå™¨äºº Novo ChatHCP!')
    # st.markdown(f'###### æ‚¨å¥½ï¼Œ:green[**{st.session_state.chat_session.rep.name}**] [ç¼–å·:green[{st.session_state.chat_session.rep.id}]]')
    st.markdown(f'###### æ­¤é¢˜çš„é¢„è®¾å¼‚è®®æ˜¯ -ã€{st.session_state.chat_session.objection.preset_objection}ã€‘')
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f'###### **æ‚¨é¢å¯¹çš„è™šæ‹ŸåŒ»ç”Ÿæ˜¯** - {st.session_state.chat_session.hcp.hcp_name}åŒ»ç”Ÿ')
        st.markdown(f"**æ€§åˆ«**:\n{st.session_state.chat_session.hcp.hcp_gender}")
        st.markdown(f"**ç§‘å®¤æ ‡ç­¾**:\n{st.session_state.chat_session.hcp.hcp_dept}")
        st.markdown(f"**æ‹œè®¿åœºæ™¯**:\n{st.session_state.chat_session.hcp.hcp_scene}")
        st.markdown(f"**åŒ»ç”Ÿåˆ†ç±»**:\n{st.session_state.chat_session.hcp.hcp_type}")
        # st.markdown(f"**æ²»ç–—è§‚å¿µ**:\n{st.session_state.chat_session.hcp.hcp_opinion}")
        st.markdown(f"**è®¤çŸ¥é˜¶æ¢¯**:\n{st.session_state.chat_session.hcp.hcp_knowledge_stage}")
        st.markdown(f"**æ²Ÿé€šé£æ ¼**:\n{st.session_state.chat_session.hcp.hcp_personality}")
        # profile = st.text_area(f'- **ä»–çš„èº«ä»½æ˜¯**', value=st.session_state.chat_session.hcp.profile)
        # opinion = st.text_area(f'- æ®æ‚¨æ‰€çŸ¥**ä»–å¯¹è¯ºå’Œæ³°çš„æ€åº¦æ˜¯**', value=st.session_state.chat_session.hcp.opinion)
        # personality = st.text_area(f'- æ®æ‚¨æ‰€çŸ¥**ä»–çš„ä¸ªæ€§æ˜¯**', value="\n".join(st.session_state.chat_session.hcp.personality))
        # new_hcp = VirtualHcp(
        #     id=st.session_state.chat_session.hcp.id,
        #     name=st.session_state.chat_session.hcp.name,
        #     gender=st.session_state.chat_session.hcp.gender,
        #     version=st.session_state.chat_session.hcp.version,
        #     profile=profile,
        #     opinion=opinion,
        #     personality=personality.split('\n'),
        #     clinic_cases=st.session_state.chat_session.hcp.clinic_cases)
        # st.session_state.chat_session.hcp = new_hcp
    with col2:
        st.image(st.session_state.image_path)

if len(st.session_state.chat_session.chat_history) == 1:
    with st.chat_message('assistant'):
        stream = st.session_state.chat_session.hcp_initiate_direct()
        response = st.write_stream(stream)
        if open_voice:
            st.audio(f'../output/audios/{st.session_state.chat_session.apply_tts}_{response}.mp3'[:MAX_LEN_FILENAME])
else:
    for i in range(len(st.session_state.chat_session.chat_history)):
        if i > 0:
            message = st.session_state.chat_session.chat_history[i]
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if message["role"] == 'assistant':
                    if open_voice:
                        st.audio(f'../output/audios/{st.session_state.chat_session.apply_tts}_{message["content"]}.mp3'[:MAX_LEN_FILENAME])

if input == st.chat_input(f"è¯·ä¸{st.session_state.chat_session.hcp.hcp_name}åŒ»ç”Ÿäº¤æµï¼Œå®Œæˆå¼‚è®®å¤„ç†"):
    prompt = input
    with st.chat_message("user"):
        st.markdown(input)

    with st.chat_message("assistant"):
        stream = st.session_state.chat_session.chat_stream(input)
        response = st.write_stream(stream)
        if open_voice:
            mp3_path, time_cost = tts_openai(response)
            st.audio(f'../output/audios/{st.session_state.chat_session.apply_tts}_{response}.mp3'[:MAX_LEN_FILENAME])

        chat_history = ''
        for each in st.session_state.chat_session.chat_history[:-2]:
            if each['role'] == 'user':
                chat_history += f"åŒ»è¯ä»£è¡¨ï¼š{each['content']}\n"
            if each['role'] == 'assistant':
                chat_history += f"åŒ»ç”Ÿï¼š{each['content']}\n"
        if not st.session_state.chat_session.session_monitor.is_confirmed:
            stage_type, process_type, is_confirmation = st.session_state.chat_session.session_monitor.c_process(chat_history, input)
            st.session_state.chat_session.session_monitor.c_skills(chat_history, input)
            print(stage_type, process_type, is_confirmation)
            output = st.session_state.chat_session.session_monitor.c_guide_process(stage_type, process_type, is_confirmation)
            if use_monitor:
                for each in output:
                    st.write(each)
        else:
            stage_type, process_type, is_in_standard_answer = st.session_state.chat_session.session_monitor.t_process(chat_history, input)
            st.session_state.chat_session.session_monitor.t_skills(chat_history, input)
            print(stage_type, process_type, is_in_standard_answer)
            output = st.session_state.chat_session.session_monitor.t_guide_process(stage_type, process_type, is_in_standard_answer)
            if use_monitor:
                for each in output:
                    st.write(each)